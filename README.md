# user_profiling_competition
## 背景简介
 

用户画像（user profiling）是指对用户的人口统计学特征、行为模式、偏好、观点、目标等进行标签化，是互联

网时代实现精准化服务、营销和推荐的必经之路，在网络安全、管理和营运等领域具有重要意义。

微博用户画像是指利用微博用户的内容信息（如发表的微博和评论）、行为记录（如浏览、转发、点赞、收藏

等）和链接结构（如用户之间的粉丝关系）等，对用户的不同维度进行画像，对完善及扩充微博用户信息、分析

微博生态以及支撑微博业务等方面具有非常重要的意义。

 

## 任务
 

参赛队伍利用给定的新浪微博数据（包括用户个人信息、用户微博文本以及用户粉丝列表，详见数据描述部

分），进行微博用户画像，具体包括以下三个任务：

任务1：推断用户的年龄（共3个标签：-1979/1980-1989/1990+）

任务2：推断用户的性别（共2个标签：男/女）

任务3：推断用户的地域（共8个标签：东北/华北/华中/华东/西北/西南/华南/境外）


## 本次使用的数据集中一共包含三类信息：

   1、社交关系信息--包含一个约256.7万微博用户构成的社交网络，其中的社交关系可能是单向的（即单向关

注，即为粉丝关系）或双向的（即互相关注，即为好友关系）。

   2、用户微博信息--包含约4.6万用户的微博文本，这些用户都属于上述社交网络。

   3、用户标签信息--包含约5千用户的年龄、性别及地域标签，这些用户都属于上述4.6万带微博文本数据的用

户。我们将基于这5千带标签的用户划分训练集、验证集和测试集。

 
 
##说明：

 

   1、训练集用于模型的学习，验证集用于在线实时评估算法效果，测试集用于最终的效果评测；

   2、训练集包含了整个数据集社交网络；

   3、验证集和测试集的用户标签信息不发布，用于组委会进行在线实时评测和最终评测。

 
## 训练集、验证集和测试集都包含有四个文件，其格式如下：

 

1、info.txt：用户信息文件

   每一行代表一个用户，包含三个属性，用||分开。包含的属性依次如下：

   uid: 用户唯一标识，由数字组成

   screen_name: 用户名，与uid一一对应，None代表此项信息缺失

   avatar_large: 用户头像的网址，None代表此项信息缺失

 

2、labels.txt：用户标签文件

   每一行代表一个用户，包含四个属性，用||分开。包含的属性依次如下：

   uid: 用户唯一标识，由数字组成

   gender: 用户性别，m代表男性，f代表女性，None代表此项信息缺失

   birthday: 用户出生年份，None代表此项信息缺失

   location: 用户地域，部分用户包含省份和城市信息，部分用户只有省份信息，None代表此项信息缺失

 

3、links.txt：用户关系文件

   每一行代表一个用户的粉丝列表，由多个用户id组成，以空格分隔，从第二个用户到最后一个用户均为第一个用

户的粉丝

 

4、status.txt：微博文本文件

   每一行代表一条用户微博，由6个属性组成，以英文逗号分隔。包含的属性依次如下：

   uid: 用户唯一标识，由数字组成

   retweet count: 转发数，数字

   review count: 评论数，数字

   source: 来源，文本

   time: 创建时间，时间戳文本(目前有两种格式，yyyy-MM-dd HH:mm:ss和yyyy-MM-dd HH:mm)

   content: 文本内容（可能包含@信息、表情符信息等）

## 实现
- 对微博文本进行提取,利用结巴分词进行分词,然后进行word2vec训练(维度设置为100),得到每个词的词向量.
- 对于每一个用户,通过其发表的微博内容,得到用户所使用的词汇,然后求得用户的平均词向量.(词向量和除以词的数量)
- 通过训练集,分别对用户地区,年龄,性别进行建模,程序采用svm模型.

> word2vec.data 为训练得到的word2vec词向量数据

> doc_dis.txt   为计算得到的用户词向量

> stopword.py  将训练集出现频率最高的100个词提取出来,写入output.txt中,然后认为观察,选取停用词

> stopwords.txt  为停用词表

> unit.py  用lda主题模型进行训练

> word2vec.py 用word2vec进行训练


